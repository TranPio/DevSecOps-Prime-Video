````markdown
How to create an EKS cluster using AWS Console | Create node group | Configure Kubernetes cluster

# Step - 1 : Create EKS Management Host in AWS #

> To install an EKS (Elastic Kubernetes Service) cluster with 2 nodes in AWS, follow these steps:

## How kubectl and eksctl Work Together?
1Ô∏è‚É£ Use `eksctl` to create the EKS cluster ‚úÖ  
2Ô∏è‚É£ Use `kubectl` to deploy & manage applications ‚úÖ  
3Ô∏è‚É£ Use `kubectl` for day-to-day operations ‚úÖ  

üëâ `kubectl` is the command-line tool for interacting with Kubernetes clusters.  
It allows you to:  
‚úî Deploy applications  
‚úî Manage resources (pods, services, deployments, etc.)  
‚úî Monitor cluster health  
‚úî Scale workloads  
‚úî Debug issues  

---

## Prerequisites
1. **AWS Account**: Make sure you have an AWS account and configure one EC2 instance.  
2. **kubectl**: Install `kubectl`.  
3. **AWS CLI**: Install and configure the AWS CLI.  
4. **eksctl**: Install `eksctl`.  

---

## Install AWS CLI and kubectl

1) **Install AWS CLI latest version** using the following commands:
   ```bash
   sudo apt install unzip
   curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
   unzip awscliv2.zip
   sudo ./aws/install
   aws --version
````

2. **Install kubectl** using the following commands:

   ```bash
   curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.19.6/2021-01-05/bin/linux/amd64/kubectl
   chmod +x ./kubectl
   sudo mv ./kubectl /usr/local/bin
   kubectl version --client
   kubectl version --short --client
   ```

3. **Install eksctl** using the following commands:

   ```bash
   curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
   sudo mv /tmp/eksctl /usr/local/bin
   eksctl version
   ```

---

# Step - 2 : Create IAM User & Attach Policies

### Create IAM user

**IAM Username:** `tranhoaiphu`

1. Go to IAM service in AWS Console ‚Üí **Users** ‚Üí **Add user** ‚Üí Set username to `tranhoaiphu`.
2. Under **Select AWS access type**, check **Programmatic access**.
3. **Attach existing policies directly**:

   * `AmazonEKSClusterPolicy`
   * `AmazonEKSWorkerNodePolicy`
   * `AmazonEC2ContainerRegistryReadOnly`
   * `IAMReadOnlyAccess` (optional)
   * `AmazonVPCFullAccess`
   * `AmazonEC2FullAccess`
   * `AdministratorAccess`
4. Complete user creation, download or copy the **Access Key ID** and **Secret Access Key**.

---

### Attach IAM Role to EKS Management Host

1. Open EC2 Console ‚Üí Select your **EKS Management Host** instance ‚Üí **Actions** ‚Üí **Security** ‚Üí **Modify IAM Role**.
2. Choose the IAM role you created for `tranhoaiphu` and attach it to the instance.

---

# Step - 3 : Create EKS Cluster & Node Group

## (a) Creating the EKS Cluster

```bash
eksctl create cluster \
  --name=TranHoaiPhu2 \
  --region=ap-northeast-1 \
  --zones=ap-northeast-1a,ap-northeast-1c \
  --version=1.30 \
  --without-nodegroup
```

**Benefits:**

* **Creates an EKS Cluster** ‚Äì Provisions an Amazon EKS cluster named `TranHoaiPhu2` without any worker nodes.
* **Multi-AZ Deployment** ‚Äì The `--zones` flag distributes the cluster across two Availability Zones (`ap-northeast-1a` and `ap-northeast-1c`) for high availability.
* **Version Control** ‚Äì Setting `--version=1.30` ensures a specific Kubernetes version for compatibility and stability.
* **Without Nodegroup** ‚Äì Allows fine-grained control over node provisioning; you‚Äôll add worker nodes separately.
* **EKS Console Verification** ‚Äì Once created, verify the cluster in the AWS EKS console under **Clusters**.

---

## (b) Associating IAM OIDC Provider

```bash
eksctl utils associate-iam-oidc-provider \
  --region ap-northeast-1 \
  --cluster TranHoaiPhu2 \
  --approve
```

**Benefits:**

* **Secure IAM Role Access for Pods** ‚Äì Enables IRSA (IAM Roles for Service Accounts), allowing Kubernetes Pods to assume IAM roles securely.
* **Prevents Over-Permission Issues** ‚Äì Without IRSA, all Pods would rely on the IAM role assigned to EC2 worker nodes, potentially granting excessive permissions.
* **Required for AWS Service Integrations** ‚Äì Many AWS services like Load Balancers, External DNS, and Auto Scaling require IRSA.
* **OIDC Authentication** ‚Äì Amazon EKS uses OpenID Connect (OIDC) to authenticate Kubernetes service accounts with IAM roles.

---

## (c) Updating the `vpc-cni` Addon with IRSA Policies

```bash
eksctl update addon \
  --name vpc-cni \
  --cluster TranHoaiPhu2 \
  --region ap-northeast-1 \
  --approve
```

**Benefits:**

* Attaches the recommended IAM policies for the `vpc-cni` addon via IRSA.
* Ensures the AWS VPC CNI plugin has the correct permissions without attaching broad EC2 node roles.

---

## (d) Creating the Node Group

Before you run this command, ensure you have an SSH key pair in EC2 named `tranhoaiphu-key`. If you haven‚Äôt created one, go to EC2 ‚Üí Key Pairs ‚Üí **Create Key Pair** ‚Üí name it `tranhoaiphu-key`.

```bash
eksctl create nodegroup \
  --cluster=TranHoaiPhu2 \
  --region=ap-northeast-1 \
  --name=nodegroup-1 \
  --node-type=t3.large \
  --nodes=2 \
  --nodes-min=2 \
  --nodes-max=4 \
  --node-volume-size=20 \
  --ssh-access \
  --ssh-public-key=tranhoaiphu-key \
  --managed \
  --asg-access \
  --external-dns-access \
  --full-ecr-access \
  --appmesh-access \
  --alb-ingress-access
```

**Benefits:**

* **Adds Managed Worker Nodes** ‚Äì Creates a managed node group, reducing maintenance overhead.
* **Optimized Resource Scaling**

  * `--nodes=2` ensures two initial worker nodes.
  * `--nodes-min=2` and `--nodes-max=4` allow auto-scaling based on demand.
* **Right-Sized Compute Power** ‚Äì `t3.large` (2 vCPU, 8 GB RAM) balances cost and performance.
* **Persistent Storage** ‚Äì `--node-volume-size=20` attaches 20 GB EBS per node.
* **Secure SSH Access** ‚Äì `--ssh-access --ssh-public-key=tranhoaiphu-key` allows SSH into nodes using key pair `tranhoaiphu-key`.
* **AWS Service Integrations**

  * `--asg-access` ‚Üí Enables Amazon Auto Scaling.
  * `--external-dns-access` ‚Üí Grants permissions for External DNS.
  * `--full-ecr-access` ‚Üí Provides full access to Amazon ECR for pulling container images.
  * `--appmesh-access` ‚Üí Enables AWS App Mesh for microservice networking.
  * `--alb-ingress-access` ‚Üí Allows Kubernetes ALB Ingress Controller to manage AWS ALB (Application Load Balancer).

---

## (e) Verifying the Cluster and Worker Nodes

1. **Update kubeconfig** so `kubectl` can talk to your new cluster:

   ```bash
   aws eks update-kubeconfig --region ap-northeast-1 --name TranHoaiPhu2
   ```
2. **Check nodes**:

   ```bash
   kubectl get nodes
   ```

   You should see the worker nodes in `Ready` state.
3. **Check addons**:

   ```bash
   eksctl get addon --cluster=TranHoaiPhu2 --region=ap-northeast-1
   ```

   You should see addons like `coredns`, `kube-proxy`, `metrics-server`, and `vpc-cni`.

---

# Step - 4 : Post-Configuration and Cleanup

## (a) Deploy a Sample Application (Optional)

1. **Create a `manifest.yml`** in your local directory. For example:

   ```yaml
   apiVersion: v1
   kind: Pod
   metadata:
     name: nginx-sample
   spec:
     containers:
       - name: nginx
         image: nginx:latest
         ports:
           - containerPort: 80
   ```
2. **Apply the manifest**:

   ```bash
   kubectl apply -f manifest.yml
   ```
3. **Verify Deployment**:

   ```bash
   kubectl get pods
   kubectl get svc
   ```

---

## (b) Cleanup Resources to Avoid Billing

When you finish your practice, delete the resources to avoid unnecessary charges:

1. **Delete Node Group**:

   ```bash
   eksctl delete nodegroup --cluster=TranHoaiPhu2 --name=nodegroup-1 --region=ap-northeast-1 --wait
   ```
2. **Disassociate IAM OIDC Provider**:

   ```bash
   eksctl utils disassociate-iam-oidc-provider --cluster=TranHoaiPhu2 --region=ap-northeast-1
   ```
3. **Delete EKS Cluster**:

   ```bash
   eksctl delete cluster --name=TranHoaiPhu2 --region=ap-northeast-1 --wait
   ```

---

# A. Verify the Cluster

After the cluster is created, verify that `kubectl` is configured to use the new cluster:

```bash
kubectl get svc
```

Expected output:

```
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.100.0.1   <none>        443/TCP   1m
```

# B. Check the Nodes

Check that the nodes are up and running:

```bash
kubectl get nodes
```

Expected output format:

```
NAME                             STATUS   ROLES    AGE   VERSION
ip-192-168-xx-xx.ec2.internal    Ready    <none>   5m    v1.17.12-eks-7684af
ip-192-168-xx-xx.ec2.internal    Ready    <none>   5m    v1.17.12-eks-7684af
```

# C. Working with Pods

1. **Apply your manifest**:

   ```bash
   kubectl apply -f manifest.yml
   ```
2. **Get pods**:

   ```bash
   kubectl get pods
   ```
3. **Describe a pod**:

   ```bash
   kubectl describe pod <pod-name>
   ```
4. **Get pod logs**:

   ```bash
   kubectl logs <pod-name>
   ```
5. **Delete a pod**:

   ```bash
   kubectl delete pod <pod-name>
   ```

---

You have successfully created an EKS cluster named **TranHoaiPhu2** with 2 nodes in AWS using `eksctl`. You can now deploy applications to your Kubernetes cluster.

**Note:** You should be able to see the EKS cluster nodes in the output of `kubectl get nodes`.

# We are done with our Setup

```
```
